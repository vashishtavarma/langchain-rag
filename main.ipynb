{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38580eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "    print(\"Set GOOGLE_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d58c064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini-2.5-flash model initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "print(\"Gemini-2.5-flash model initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4573a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Generative AI Embeddings initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "print(\"Google Generative AI Embeddings initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f9e2475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-memory vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "print(\"In-memory vector store created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ce4cf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded document with 7005 characters\n",
      "Document loaded successfully!\n",
      "[Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='# M VASHISHTA VARMA - Professional Profile\\n\\n## Overview\\nA dedicated software developer and AI/ML enthusiast with expertise in Python development, web applications, data compression algorithms, and news analysis systems. Demonstrated proficiency in building end-to-end applications with modern frameworks and implementing advanced machine learning solutions.'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='## GitHub Profile Summary\\n- **Username**: vashishtavarma\\n- **Repositories**: 9 active repositories\\n- **Followers**: 10 | Following: 10\\n- **Achievements**: YOLO, Pull Shark x2, Quickdraw\\n- **Primary Language**: Python\\n- **Account Status**: PRO\\n\\n## Technical Skills & Expertise\\n\\n### Programming Languages\\n- **Python** (Primary)\\n- HTML/CSS\\n- JavaScript'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='### Programming Languages\\n- **Python** (Primary)\\n- HTML/CSS\\n- JavaScript\\n\\n### Frameworks & Technologies\\n- **Web Development**: Flask, Django, JavaScript\\n- **Frontend**: Bootstrap, HTML5, CSS3, Jinja2 templating\\n- **Database**: SQLite, Django ORM\\n- **Machine Learning**: Transformers, Hugging Face, FinBERT\\n- **Data Processing**: Pandas, NumPy\\n- **Version Control**: Git, GitHub\\n- **Testing**: Pytest\\n- **Deployment**: WSGI, ASGI'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='### Specialized Areas\\n- **Algorithm Implementation**: Huffman Coding, Data Compression\\n- **AI/ML**: Sentiment Analysis, Natural Language Processing\\n- **Web Scraping**: Google News API, BeautifulSoup\\n- **News Aggregation & Analysis**\\n- **Data Visualization & Processing**\\n\\n## Featured Projects\\n\\n### 1. HuffComp - PDF Compression Tool ⭐ 2 Stars\\n**Repository**: `huff-comp`\\n**Technologies**: Python, Flask, HTML/CSS, Huffman Coding Algorithm'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='**Key Features**:\\n- PDF compression using Huffman encoding algorithm\\n- Web-based interface for file upload/download\\n- Byte-level frequency analysis with binary tree encoding\\n- Expected compression ratios: 20-70% depending on content type\\n- Responsive design with custom CSS styling'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='**Technical Highlights**:\\n- Implemented complete Huffman coding algorithm from scratch\\n- Built Flask web application with file handling capabilities\\n- Created efficient binary data processing system\\n- Developed user-friendly interface with drag-and-drop functionality\\n- Added comprehensive error handling and file validation'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='**Architecture**:\\n```\\nhuff-comp/\\n├── web/\\n│   ├── main.py              # Flask application & Huffman implementation\\n│   ├── huffmanCoding.py     # Alternative Huffman coding module\\n│   ├── static/styles.css    # Custom CSS styling\\n│   ├── templates/index.html # Web interface\\n│   └── uploads/             # File processing directories\\n```\\n\\n### 2. AI News Analysis Application ⭐ 2 Stars\\n**Repository**: `ai-news-analysis`\\n**Technologies**: Django, FinBERT, Google News API, Bootstrap, Pytest'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='**Key Features**:\\n- Real-time news sentiment analysis using FinBERT model\\n- Multi-region news aggregation (India, US)\\n- Dynamic categorization by sentiment (Positive, Negative, Neutral)\\n- User authentication and authorization system\\n- Responsive web interface with dark theme'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='**Technical Implementation**:\\n- **Sentiment Analysis**: Integrated ProsusAI/FinBERT for financial sentiment analysis\\n- **Data Pipeline**: Automated news scraping, sentiment analysis, and database storage\\n- **Web Framework**: Django 5.2 with custom models and views\\n- **Database Design**: Relational model with Region, Sentiment, Category, and NewsArticle entities\\n- **Security**: Environment variable configuration, production-ready security settings'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='- **Security**: Environment variable configuration, production-ready security settings\\n- **Testing**: Comprehensive test suite using Pytest'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='**Architecture & Models**:\\n- **Region Model**: Supports multiple countries (India, US)\\n- **Sentiment Model**: Three-tier sentiment classification\\n- **Category Model**: Dynamic news categorization (Politics, Business, Technology, Sports, Health)\\n- **NewsArticle Model**: Complete article metadata with unique URL constraints'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='### 3. Blockchain Crypto Contract ⭐ 2 Stars\\n**Repository**: `blockchain-crypto-contract`\\n**Technologies**: Python\\n- Smart contract development and blockchain integration\\n- Cryptocurrency-related functionalities\\n\\n### 4. AWS RAG Implementation ⭐ 1 Star\\n**Repository**: `aws-rag`\\n**Technologies**: Python, AWS Services\\n- Retrieval-Augmented Generation system on AWS\\n- Cloud-based AI/ML pipeline implementation'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='### 5. RAG Playground ⭐ 1 Star\\n**Repository**: `rag-playground`\\n**Technologies**: HTML, Python\\n- Experimental RAG (Retrieval-Augmented Generation) implementations\\n- Interactive playground for testing RAG systems\\n\\n### 6. Weather Application\\n**Repository**: `weather`\\n**Technologies**: HTML\\n- Weather information display application\\n- Frontend-focused development\\n\\n## Development Practices & Methodologies'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='## Development Practices & Methodologies\\n\\n### Code Quality & Testing\\n- **Testing Framework**: Pytest with comprehensive test coverage\\n- **Code Organization**: Modular architecture with separation of concerns\\n- **Documentation**: Detailed README files with setup instructions\\n- **Version Control**: Git with meaningful commit messages and branching'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='### Security & Best Practices\\n- Environment variable management for sensitive data\\n- Production-ready security configurations\\n- Input validation and error handling\\n- HTTPS/SSL configuration for production deployments\\n\\n### Project Management\\n- Clear project structure and documentation\\n- Step-by-step setup instructions\\n- Comprehensive API documentation\\n- Performance optimization considerations\\n\\n## Technical Achievements'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='## Technical Achievements\\n\\n### Algorithm Implementation\\n- **Huffman Coding**: Complete implementation with binary tree construction\\n- **Frequency Analysis**: Efficient byte-level data processing\\n- **Compression Optimization**: Achieved 20-70% file size reduction'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='### Machine Learning Integration\\n- **Sentiment Analysis**: FinBERT model integration for financial news\\n- **Data Pipeline**: Automated ML workflow from data ingestion to analysis\\n- **Real-time Processing**: Live news sentiment classification\\n\\n### Web Development\\n- **Full-Stack Applications**: End-to-end web application development\\n- **Responsive Design**: Mobile-friendly interfaces with modern CSS\\n- **User Experience**: Intuitive interfaces with proper error handling\\n\\n## Professional Skills'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='## Professional Skills\\n\\n### Problem Solving\\n- Algorithm design and optimization\\n- Complex system architecture\\n- Performance bottleneck identification and resolution\\n\\n### Software Development\\n- Full software development lifecycle experience\\n- Modern development practices and tools\\n- Cross-platform compatibility considerations\\n\\n### Data Processing\\n- Large-scale data aggregation and processing\\n- Real-time data pipeline implementation\\n- Database design and optimization'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='## Current Focus Areas\\n- Advanced RAG (Retrieval-Augmented Generation) systems\\n- Cloud-based AI/ML deployments\\n- Blockchain and cryptocurrency technologies\\n- News analysis and sentiment processing\\n- Web application development with modern frameworks\\n\\n## Contact Information\\n- **GitHub**: https://github.com/vashishtavarma\\n- **LinkedIn**: https://www.linkedin.com/in/m-vashishta-varma-134b1529a/\\n\\n---'), Document(metadata={'source': 'document.txt', 'type': 'professional_profile', 'author': 'M Vashishta Varma'}, page_content='---\\n\\n*This document represents a comprehensive analysis of technical projects and capabilities based on publicly available GitHub repositories and professional profiles.*')]\n",
      "Application compiled successfully.\n",
      "Application compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Read the document.txt file\n",
    "with open(\"document.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Create a Document object\n",
    "docs = [Document(\n",
    "    page_content=content,\n",
    "    metadata={\n",
    "        \"source\": \"document.txt\",\n",
    "        \"type\": \"professional_profile\",\n",
    "        \"author\": \"M Vashishta Varma\"\n",
    "    }\n",
    ")]\n",
    "\n",
    "print(f\"Loaded document with {len(content)} characters\")\n",
    "print(\"Document loaded successfully!\")\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(all_splits)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Load prompt from hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "print(\"Application compiled successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df44a946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vashishta has the GitHub achievements of YOLO, Pull Shark x2, and Quickdraw. He currently has 9 active repositories.\n"
     ]
    }
   ],
   "source": [
    "# \"What GitHub achievements does Vashishta have?\"\n",
    "# \"How many repositories does Vashishta have?\"\n",
    "# \"What is Vashishta's primary programming language?\"\n",
    "# \"Explain the Huffman coding implementation\"\n",
    "# \"What web technologies are used in the projects?\"\n",
    "# \"How is the Flask application structured?\"\n",
    "# \"What testing frameworks are mentioned?\"\n",
    "# \"What are Vashishta's specialized areas?\"\n",
    "# \"What kind of applications has Vashishta built?\"\n",
    "# \"What databases has Vashishta worked with?\"\n",
    "# \"What deployment technologies are mentioned?\"\n",
    "\n",
    "response = graph.invoke({\"question\": \"What GitHub achievements does Vashishta have and how many repositories does he have?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
